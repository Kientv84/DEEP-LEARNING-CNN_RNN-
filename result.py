# -*- coding: utf-8 -*-
"""RESULT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XzsCimKaG1Uyvuk2gSCQN4kKSLURym2a
"""

import numpy as np
import cv2
from google.colab.patches import cv2_imshow
import requests
import matplotlib.pyplot as plt



"""**Mounted drive**

**Helper Function**
"""

def _downloadImage(url):
  resp = requests.get(url)
  img = np.asarray(bytearray(resp.content), dtype="uint8")
  img = cv2.imdecode(img, cv2.IMREAD_COLOR)
  return img

def _drawBoundingBox(img, cnt):
  x,y,w,h = cv2.boundingRect(cnt)
  img = cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,0),2)
  return img

def _cropImage(x1, y1, x2, y2, img):
  if np.ndim(img) == 3:
    crop = img[y1:y2, x1:x2, :]
  else:
    crop = img[y1:y2, x1:x2]
  return crop

"""**Preprocessing**"""

def preprocessing(url):
  img = cv2.imread(url)
  _, imgBi = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)
  imgGrayBi = cv2.cvtColor(imgBi, cv2.COLOR_BGR2GRAY)

  contours, _ = cv2.findContours(imgGrayBi, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
  area_cnt = [cv2.contourArea(cnt) for cnt in contours]
  area_sort = np.argsort(area_cnt)[::-1][:12]
  return (area_cnt, area_sort, contours, img)

"""**Remove box bounding (background box)**"""

def removeBoundingBox(area_cnt, area_sort):
  save = 1
  for i in area_sort[1:]:
      # print(area_cnt[area_sort[save - 1]], area_cnt[area_sort[save]])
      if area_cnt[area_sort[save - 1]] // area_cnt[area_sort[save]] > 9:
        break
      else:
        save += 1
  area_sort = area_sort[save:]
  return area_sort

"""**Non-max-suppression**"""

def non_max_suppression(boxes, overlapThresh):
    if len(boxes)==0:
       return []

    if boxes.dtype.kind == "i":
      boxes = boxes.astype("float")

    pick = []
    x1 = boxes[:,0]
    y1 = boxes[:,1]
    x2 = boxes[:,2]
    y2 = boxes[:,3]

    area = (x2 - x1 + 1) * (y2 - y1 + 1)
    idxs = np.argsort(y2)

    while len(idxs) > 0:
        last = len(idxs) - 1
        i = idxs[last]
        pick.append(i)

        xx1 = np.maximum(x1[i], x1[idxs[:last]])
        yy1 = np.maximum(y1[i], y1[idxs[:last]])
        xx2 = np.minimum(x2[i], x2[idxs[:last]])
        yy2 = np.minimum(y2[i], y2[idxs[:last]])

        w = np.maximum(0, xx2 - xx1 + 1)
        h = np.maximum(0, yy2 - yy1 + 1)

        iou = (w * h) / area[idxs[:last]]

        idxs = np.delete(idxs, np.concatenate(([last],np.where(iou > overlapThresh)[0])))

    return boxes[pick].astype("int")

def get_pick(area_sort, contours, img):
  boundingBoxes = []
  for i in area_sort:
    cnt = contours[i]
    x,y,w,h = cv2.boundingRect(cnt)
    x1, y1, x2, y2 = x, y, x+w, y+h
    boundingBoxes.append((x1, y1, x2, y2))

  boundingBoxes = [box for box in boundingBoxes]
  boundingBoxes = np.array(boundingBoxes)
  pick = non_max_suppression(boundingBoxes, 0.5)
  imgOrigin = img.copy()
  for (startX, startY, endX, endY) in pick:
      imgOrigin = cv2.rectangle(imgOrigin, (startX, startY), (endX, endY), (0, 255, 0), 2)
  pick = sorted(pick,key = lambda x : x[0] * x[1])
  pick = [e for e in pick if imgOrigin.shape[0]/abs(e[0] - e[2]) > 2 and imgOrigin.shape[1]/abs(e[1] - e[3]) > 2]
  return pick

def get_peak(pick):
  peak = []
  candidate = pick[0][0]
  for i in range(1,len(pick)):
      if pick[i][0] < candidate:
        peak.append(i)
      candidate = pick[i][0]
  return peak

def get_crops_image(pick, peak, img):
  #pick_const = []
  #pick_alternate = []
  if len(peak) > 1:
    row2 = peak[:-1]
    pick_const = [e for i,e in enumerate(pick) if i not in row2 and i < peak[-1]]
    pick_alternate = [pick[i] for i in row2]
    pick = pick_const + pick_alternate + pick[peak[-1]:]
  crop_images = [_cropImage(x1, y1, x2, y2, img) for (x1, y1, x2, y2) in pick]
  return crop_images

"""PREDICT

"""

list_labels = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z']

import tensorflow as tf
model = tf.keras.models.load_model('/content/Model_classification.h5')

def preprocessing_image(image):
  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
  image = cv2.resize(image, (128, 128))
  image = image.astype('float32')
  image = image / 255.0
  return image

def show_predict(img, crops_image, model):
  plt.figure(figsize=(5, 10))
  plt.imshow(img)
  plt.title('Prediction value: ' + print_predict(crops_image, model), size = 20, color = "black")
  print(img.shape)
  plt.xticks([])
  plt.yticks([])
  plt.show()

def print_predict(crop_images, model):
    result = str()
    for i in range(len(crop_images)):
        result += list_labels[np.argmax(model.predict(np.array([preprocessing_image(crop_images[i])])))]
    return result

def predict(url, model):
  area_cnt, area_sort, contours, img = preprocessing(url)
  area_sort = removeBoundingBox(area_cnt, area_sort)
  pick = get_pick(area_sort, contours, img)
  peak = get_peak(pick)
  crops_image = get_crops_image(pick, peak, img)

  show_predict(img, crops_image, model)

predict('/content/img2.jpg', model)

predict('/content/BienSo4.jpg', model)